{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c421be7-afd3-4b31-87b5-61f8541a1c24",
   "metadata": {},
   "source": [
    "# Practical 2: Multi-Armed Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cfda4e-37e0-4bb9-aea2-14fb4678b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a5c23-9356-4ac6-9e27-2ef58d14adb3",
   "metadata": {},
   "source": [
    "## Basic Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331d0eaf-95a7-4d09-a883-0ff8625e0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "\n",
    "    def step(self, a):\n",
    "        self.state += 1\n",
    "        reward = -1\n",
    "        next_observation = 10 * self.state\n",
    "        return next_observation , reward\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        return self.state\n",
    "    \n",
    "    def render(self):\n",
    "        print(self.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98422f21-09b3-453d-813b-ecd72787b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "obs = env.reset()\n",
    "for _ in range(10):\n",
    "    obs, rew = env.step(0)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4469f31-bcb6-450e-aa65-a1a125f8b8ac",
   "metadata": {},
   "source": [
    "## Multi-Armed Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fc3be2-0459-4903-968b-e309a200edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditEnv():\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "        self.n_actions = 6\n",
    "        self.n_states = 0\n",
    "        self.probs = np.array([0.4, 0.2, 0.1, 0.1, 0.1, 0.7])\n",
    "        self.rewards = np.array([1.0, 0.1, 2.0, 0.5, 6.0, 70.])\n",
    "    \n",
    "    def step(self, a):\n",
    "        reward = -25\n",
    "        if np.random.uniform() < self.probs[a]:\n",
    "            reward += self.rewards[a]\n",
    "        return self.state, reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f04370c4-d7e0-4e49-a009-0d389d8e4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def sample_action(self, observation=0):\n",
    "        return np.random.randint(self.env.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba359f44-933b-4b3e-855a-e07b4eb9d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about -15548.89999999999\n",
      "about [-24.55688623 -24.97832168 -24.78231293 -24.96774194 -24.45454545\n",
      "  26.04972376]\n"
     ]
    }
   ],
   "source": [
    "env = BanditEnv()\n",
    "agent = Agent(env)\n",
    "o = env.reset()\n",
    "money = 0\n",
    "money_per_machine = np.zeros(env.n_actions)\n",
    "usage_per_machine = np.zeros(env.n_actions)\n",
    "for episode in range(1000):\n",
    "    a = agent.sample_action(o)\n",
    "    o, r = env.step(a)\n",
    "    money += r\n",
    "    money_per_machine[a] += r\n",
    "    usage_per_machine[a] += 1\n",
    "print(\"about \" + str(money))\n",
    "print(\"about \" + str(money_per_machine/usage_per_machine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bbdeb-fe3e-4443-8732-04bfb851580a",
   "metadata": {},
   "source": [
    "###  Solving Multi-Armed Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02de0a9-b09b-4138-963e-2ca4233b4b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80.  18.  15.  16.  17. 854.]\n",
      "[-24.43928822 -24.40312392 -23.83289782 -24.03443309 -23.09102269\n",
      "  -2.28843795]\n",
      "[-24.4446285  -28.71275397 -30.01212867 -29.50103395 -27.7127237\n",
      "  -2.28843792]\n"
     ]
    }
   ],
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(self, env, alpha=None, epsilon=0):\n",
    "        self.env = env\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.k = np.zeros(self.env.n_actions)\n",
    "        self.q = np.zeros(self.env.n_actions)\n",
    "\n",
    "    @property\n",
    "    def q_corrected(self):\n",
    "        if self.alpha is None:\n",
    "            return self.q\n",
    "        else:\n",
    "            return self.q / (1 - (1 - self.alpha)**self.k + 1e-8)\n",
    "\n",
    "    def put_data(self, action, reward):\n",
    "        self.k[action] += 1\n",
    "        if self.alpha is None:\n",
    "            # exact average\n",
    "            if self.k[action] == 1:\n",
    "                self.q[action] = r\n",
    "            else:\n",
    "                self.q[action] += (r - self.q[action]) / self.k[action]\n",
    "        else:\n",
    "            # smoothing average\n",
    "            self.q[action] += self.alpha * (r - self.q[action])\n",
    "\n",
    "            self.q[action] = (1 - self.alpha) * self.q[action] + self.alpha * r\n",
    "        \n",
    "    def sample_action(self, state=0, epsilon=0.4):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(env.n_actions)\n",
    "        else:\n",
    "            return np.argmax(self.q_corrected)\n",
    "\n",
    "env = BanditEnv()\n",
    "agent = Agent(env=env, alpha=0.1, epsilon=0.1)\n",
    "s = env.reset()\n",
    "for episode in range(1000):\n",
    "    a = agent.sample_action(s)\n",
    "    s, r = env.step(a)\n",
    "    # learn to estimate the value of each action\n",
    "    agent.put_data(a, r)\n",
    "\n",
    "print(agent.k)\n",
    "print(agent.q)\n",
    "print(agent.q_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1389f-6139-4885-8449-b5a39b4f5a65",
   "metadata": {},
   "source": [
    "## Multi-Armed Multi-Room Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd706e18-39c5-4923-b4a5-b0213f2dcd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.         -17.1547351  -13.0425775  -17.93926159 -11.713975\n",
      "   -8.5975     -11.713975  ]\n",
      " [  0.         -24.09144362 -24.56012189 -24.33026065 -24.45210762\n",
      "  -24.0249469   22.99010811]\n",
      " [  0.         -17.93926159 -13.0425775  -11.713975   -16.283039\n",
      "  -20.36744953 -13.0425775 ]]\n"
     ]
    }
   ],
   "source": [
    "class BanditEnv():\n",
    "    def __init__(self):\n",
    "        self.n_actions = 6+1\n",
    "        self.n_states  = 3\n",
    "        self.probs = np.array([\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 0.4, 0.2, 0.1, 0.1, 0.1, 0.7],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        ])\n",
    "        self.rewards = np.array([\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ],\n",
    "            [0.0, 1.0, 0.1, 2.0, 0.5, 6.0, 70.0],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ],\n",
    "        ])\n",
    "\n",
    "    def step(self, s, a):\n",
    "        r = -25\n",
    "\n",
    "        # if first action taken, move to next state with no reward\n",
    "        if a == 0:\n",
    "            return (s+1)%3, 0\n",
    "        # else pull the slot machine and get the reward, stay in current room\n",
    "        if np.random.uniform() < self.probs[s, a]:\n",
    "            r += self.rewards[s,a]\n",
    "\n",
    "        return s, r\n",
    "    \n",
    "    def reset(self):\n",
    "        return 0\n",
    "        \n",
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.q = np.zeros([env.n_states, env.n_actions])\n",
    "\n",
    "    def sample_action(self, state=0, epsilon=0.4):\n",
    "        if np.random.rand() > epsilon:\n",
    "            return np.argmax(self.q[state,:])\n",
    "        else:\n",
    "            return np.random.randint(env.n_actions)\n",
    "\n",
    "env = BanditEnv()\n",
    "s = env.reset()\n",
    "agent = Agent()\n",
    "for episode in range(1000):\n",
    "    a = agent.sample_action(s)\n",
    "    next_s,r = env.step(s,a)\n",
    "    \n",
    "    agent.q[s,a] += 0.1 * (r - agent.q[s,a])\n",
    "    s = next_s\n",
    "    \n",
    "print(agent.q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
