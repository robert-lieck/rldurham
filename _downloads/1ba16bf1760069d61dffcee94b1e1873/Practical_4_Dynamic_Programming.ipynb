{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Practical 4: DynamicProgramming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# # Practical 4: DynamicProgramming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport rldurham as rld\n\n\n# ## Frozen Lake Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env = rld.make(\n    'FrozenLake-v1',         # small version\n    # 'FrozenLake8x8-v1',    # larger version\n    # desc=[\"GFFS\", \"FHFH\", \"FFFH\", \"HFFG\"],  # custom map\n    render_mode=\"rgb_array\", # for rendering as image/video\n    is_slippery=False,       # warning: slippery=True results in complex dynamics\n)\nrld.env_info(env, print_out=True)\nrld.seed_everything(42, env)\nLEFT, DOWN, RIGHT, UP = 0, 1, 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# render the environment (requires render_mode=\"rgb_array\")\nrld.render(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# helper function that can also plot policies and value functions\nrld.plot_frozenlake(env=env,\n                    v=np.random.uniform(0, 1, 16),\n                    policy=np.random.uniform(0, 1, (16, 4)), \n                    draw_vals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def uniform_policy(env):\n    return np.ones((env.observation_space.n, env.action_space.n)) / env.action_space.n\nrld.plot_frozenlake(env=env, policy=uniform_policy(env))\n\n\n# ## Policy Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def policy_eval_step(env, policy, gamma, v_init=None):\n    if v_init is None:\n        v_init = np.zeros(env.observation_space.n)\n    v = np.zeros(env.observation_space.n)\n    for s_from in range(env.observation_space.n):\n        for a in range(env.action_space.n):\n            pi = policy[s_from, a]\n            for p, s_to, r, done in env.P[s_from][a]:\n                v[s_from] += pi * p * (r + gamma * v_init[s_to])\n    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = np.zeros(env.observation_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = policy_eval_step(env, uniform_policy(env), 1, v)\nrld.plot_frozenlake(env, v, uniform_policy(env), draw_vals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def policy_eval_step_inplace(env, policy, gamma, v_init=None):\n    if v_init is None:\n        v_init = np.zeros(env.observation_space.n)\n    v = v_init.copy() # opearate on copy in-place\n    for s_from in reversed(range(env.observation_space.n)):  # reverse order of states\n        v_s_from = 0  # compute value for this state\n        for a in range(env.action_space.n):\n            pi = policy[s_from, a]\n            for p, s_to, r, done in env.P[s_from][a]:\n                v_s_from += pi * p * (r + gamma * v[s_to])  # use the values we also update\n        v[s_from] = v_s_from  # update\n    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = np.zeros(env.observation_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = policy_eval_step_inplace(env, uniform_policy(env), 1, v)\nrld.plot_frozenlake(env, v, uniform_policy(env), draw_vals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(env, policy, gamma, v_init=None, print_iter=False, atol=1e-8, max_iter=10**10):\n    if v_init is None:\n        v_init = np.zeros(env.observation_space.n)\n    v = v_init\n    for i in range(1, max_iter + 1):\n        new_v = policy_eval_step(env, policy, gamma, v)\n        # new_v = policy_eval_step_inplace(env, policy, gamma, v)\n        if np.allclose(v, new_v, atol=atol):\n            break\n        v = new_v\n    if print_iter:\n        print(f\"{i} iterations\")\n    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = policy_evaluation(env, uniform_policy(env), 1, print_iter=True)\nrld.plot_frozenlake(env, v, uniform_policy(env), draw_vals=True)\n\n\n# ## Policy Improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def q_from_v(env, v, s, gamma):\n    q = np.zeros(env.action_space.n)\n    for a in range(env.action_space.n):\n        for p, s_to, r, done in env.P[s][a]:\n            q[a] += p * (r + gamma * v[s_to])\n    return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def policy_improvement(env, v, gamma, deterministic=False):\n    policy = np.zeros([env.observation_space.n, env.action_space.n]) / env.action_space.n\n    for s in range(env.observation_space.n):\n        q = q_from_v(env, v, s, gamma)\n        if deterministic:\n            # deterministic policy\n            policy[s][np.argmax(q)] = 1\n        else:\n            # stochastic policy with equal probability on maximizing actions\n            best_a = np.argwhere(q==np.max(q)).flatten()\n            policy[s, best_a] = 1 / len(best_a)\n    return policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env = rld.make('FrozenLake8x8-v1', is_slippery=False)\nrld.seed_everything(42, env)\ngamma = 1\npolicy = uniform_policy(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = policy_evaluation(env, policy, gamma=gamma)\nrld.plot_frozenlake(env, v=v, policy=policy, draw_vals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "policy = policy_improvement(env, v, gamma=gamma)\nrld.plot_frozenlake(env, v=v, policy=policy, draw_vals=True)\n\n\n# ## Policy Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env = rld.make('FrozenLake8x8-v1', is_slippery=False)\nrld.seed_everything(42, env)\npolicy = uniform_policy(env)\ngamma = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = policy_evaluation(env, policy, gamma=gamma)\nrld.plot_frozenlake(env, v=v, policy=policy, draw_vals=True)\nprint(v)\npolicy = policy_improvement(env, v, gamma=gamma)\nrld.plot_frozenlake(env, v=v, policy=policy, draw_vals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env = rld.make(\n    'FrozenLake-v1',\n    desc=[\n        \"FFF\",\n        \"FHF\",\n        \"SFG\",\n        \"FHF\",\n    ],\n    is_slippery=True,\n    render_mode='rgb_array',\n)\nrld.seed_everything(42, env)\nrld.render(env)\n\n\n# `gamma = 1`: Preference for longer but low-risk paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gamma = 1\npolicy = uniform_policy(env)\nfor _ in range(10):\n    v = policy_evaluation(env, policy, gamma=gamma)\n    policy = policy_improvement(env, v, gamma=gamma)\n    rld.plot_frozenlake(env, v=v, policy=policy, draw_vals=False, clear=True)\n\n\n# `gamma < 1`: Preference for shorter but potentially riskier paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gamma = 0.5\npolicy = uniform_policy(env)\nfor _ in range(10):\n    v = policy_evaluation(env, policy, gamma=gamma)\n    policy = policy_improvement(env, v, gamma=gamma)\n    rld.plot_frozenlake(env, v=v, policy=policy, draw_vals=False, clear=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}